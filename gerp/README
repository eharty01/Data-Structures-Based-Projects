(A) *Title, Course, Date, and Authors of HW*
___________________________________________
Title of Assignment: Gerp (Project 4)
Authors: Eleanor Harty and Allen Wang
Date: Dec. 3, 2023
Course: CS15

(B) PROGRAM PURPOSE
___________________

The purpose of this program is to provide a way to search through a
given directory (and its subdirectories and files) for a user given word. It
will print the results of this search to an output file, if the search is
successful it will include where to find the line if it is unsuccessful it
will let the user know there. The user can also switch which output file they
want their results to print to.

(C) ACKNOWLEDGEMENTS
____________________

We received help from Vedant, Alana, Cameron, Erin, Hameedah, Ollie, Liam,
Matt, and Kathy.

(D) FILES PROVIDED
__________________

stringProcessing.h:
    Interface of the stringProcessing class.

stringProcessing.cpp:
    Implementation of the stringProcessing class.

Command.h:
    Interface of the Command class.

Command.cpp:
    Implementation of the Command class.

Makefile:
    Builds an executable for our gerp program.

main.cpp:
    Calls the gerp program to start.

README
     This file.

duplicates.in
    testing file for case of the same word occuring on the same line.

empty_file.in
    testing file for how our program handles an empty file.

i_vs_s.in
    testing file to see how well our program can find results for sensitive
    and insensitive searches (as well as when words in the file have characters
    attached to them).

no_result.in
    testing file to see if our program prints the correct

same_line_query.in
    testing file for if a user places a space between words before hitting 
    enter the program will respond correctly

newOutputFile.in
    this file was made to test if our @f command was working

non_word.in
    this file was made to test if our program worked properly when given an
    input that did not fit the program's definition of a word

multiple.in
    this file was made to test if our program worked properly when given the
    same input multiple times

apple
    a directory we made within the gerp directy to pass in, it contains 
    directories and files that we used in earlier tests (provided because
    many of the .in files use words from apple). Since we can't pass in the
    whole directory we gave the files we were calling words from namely
    sub_dir_test_a, sub_dir_test_b, single_word_special_characters.txt, and
    test1.txt

(E) COMPILE/RUN
_______________

Final gerp:
    - Compile using
        make gerp
    - run with ./gerp inputDirectory outputFile

For Phase 1:
     - Compile using
        make treeTraversal
     - run with ./treeTraversal

(F) ARCHITECTURAL OVERVIEW
__________________________

To run the gerp program we start in main where (assuming the user has provided
valid input) an FSTree will be built for the provided directory and a pointer 
to the root of that tree will be created and passed to the instance of the 
Command class that will also be created in main which command will use to 
traverse teh existing files and subdirectories and store their names. It will 
then run the Command class which will allow the user to input commands and 
search for words within their provided directory.

Command builds a hash table composed of a vector of lists. This
table contains as a key the first word that is hashed into it (in the format
of how a word is defined in the spec and in all lower case letters thanks
to functions stored in the stringProcessing class that remove nonalpahnumeric
characters from the front and end of a word and can format it into all lower
case letters). The second vector allows us handle collisions if multiple
words are hashed to the same bucket and finally the list contains structs of
word specific information.

Specifically, Command defines a struct called KeyValueInfo, this struct stores 
important information about the location of the word for us to print later if 
the user searches for it (such as file path, line number, and the original 
word being saved).

(G) DATA STRUCTURES
___________________

Data Structures:

VECTORS
Vectors use contiguous storage for elements, internally they do this via 
dynamically allocated arrays, they can carry out many different commands like 
push_back, erase, begin, size and front. But the main one we used for our 
program was at which allowed us to access an index at a specific point in the 
vector. Some advantages of vectors is that they resize themselves dynamically 
and allocate/eallocate memory. They also provide quick access to elements. 
Finally, a disadvantage of vectors are that inserting or removing elements not 
at the end is inefficient as you need to shift the ohter elements. 

In this assignment we used a vectors to store the keys of the hash table. Each
unique word was hashed into a spot in the vector contained a list of values.

LISTS
Lists use noncontiguous storage for elements, internally they do this with 
doubly linked lists. They can also perform many different commands for users 
but the main one we used for this project was push_back. Some advantages of 
lists are that the time taken to insert or delete something from the front, 
middle, or back of the list is constant time. A disadvantage of lists is that 
to access an element an element not at the front of the list you have to 
traverse the list unitl you find it, but since stacks only deal with the front 
this drawback didn't hurt lists much as a tool specifically to implement them.

In our program we used lists as the value part of the key value pair in hash 
tables to store structs of each word and its key information that we would need
later for printing such as it's line number and file path. Lists were the ideal
choice for this because since they provide quick access times to the back we 
were able to quickly add structs without taking up too much time. Additionally 
since lists can dynamically shrink and expand their initial size does not need 
to defined and we can add as many structs as we need to the list without 
'running out of space'. This was very helpful both for larger data sets where 
they could be many repeats for each word and it also handled collisions through
chaining. If a word was hashed to the same bucket on the hash table the struct 
for the new word could still be pushed back and we can check before we print 
that the word is actually the one the user queried for and not the another word 
that happened to be hashed there by checking the original word member of the 
struct.

HASH TABLE
Hash tables are data structures which utilize key value pairing to allow
constant time look up for values within the hash table. The way they accomplish
this is by using a hash function which creates a index from a provided key (in
our program a word) that from then on values associated with that key can be
found at that index. The main advantage of hash tables is their ability to
provide the best possible time complexity (O(1)) for retrieval. Their main 
drawback is that when two keys are hashed to the same bucket this creates a 
collision and collisions can slow down constant time retrieval.

We used hash tables for this assignment as handling such large amounts of data
makes traversing through the data structure to find what we're looking for 
incredibly inefficient, we needed fast access to the data hash tables were able
to provide retrieval at a consistently fast time complexity. We 
created our hash table as a vector of lists and used a hash function to assign
a spot in the vector to a key, once that was done we stored the values
associated with that key on the list.

Algorithms:

TRAVERSER
Traverser relies on file trees (a hierarchical data structure that categorizes
how a computer stores information as subdirectories or files). This was useful
for the assignment as it gave us a quick way to access files for opening and 
reading them. In traverser we first look for files if we can't find them we
look for a subdirectory and then recursively call traverser to look through the
subdirectory for files to open. A string variable called path keeps track of 
the current file so when we do get to a file and call a function to read from 
that file we can pass to the read function the name of the file we want it to 
open and read into.

PERFORM SEARCH
In perform search we pass in the word that the user queried, a bool indicating
what kind of search the user requested, and the output file we want to print
to. We then call our hash function to find the index where this particular 
word is stored and then iterate through the list at that key to check if the
key matches the word the user queried for insensitive search (as the key is
always lowered), if so we print. For the sensitive search we match the query in
its original form with the original form as stored in the struct and then
based on that call the other function to print the word or not.

(H) TESTING
___________

Phase One:

For Phase One testing we used print statements to see if our output was
matching what we knew the reference would require. For example printing out
our strings after then went through string processing to ensure they looked
like what the spec defined as a word. And also ensuring our print statement
for the directories matched the example given in the spec (obviously it didn't
include the line number and phrase yet but making sure the general format of 
how they displayed subdirectories and files were the same). For traversing the 
tree a problem we had was that the program would either throw a runtime error. 
Eventually we realized this was because we had confused the
parameter for our for loop that searched for files (we used the number of 
subdirectories instead of the number of files as our loop condition). Once we
fixed that our program ran well. Another problem with loop conditions was our 
condition for a while loop in stripNonAlphaNum because we were trying to 
write a mathematic inequality (like 65 <= char <= 90) to test if the character
was a number/letter or not and the computer saw this as trying to compare a 
bool to an int so we had to add parentheses and the 'and' command to our
condition for the computer to interpret it the way we had intended it to. After
that the program seemed to work correctly but when we submitted it to 
GradeScope we got a build error, which we were able to fix after realizing we
had named the function incorrectly. 

Phase Two:

For this phase we mostly used diff testing. Throughout the process of building
the functions that created the structs we used cout statements in our insertion
statement to verify that the size of each list was correct as well as the 
information being passed into each struct. This process worked fairly well so
we knew our hash table was building correctly. From there we moved onto 
building the query loop and the search/print functions. One problem we had
with the query loop was ensuring that the quit statement only printed once so
we moved it to the end of the wrapper function to start gerp to ensure it would
only occur once. From there we moved to harder commands and after building our
search and print functions began to test them with simple commands from our
own small directory we made called apple. We tried to consider as many edge
cases as possible testing for providing too few or too many arguments, or
providing an empty directory (these passed without much having to rewrite).
Then we tried to test cases in searching and printing, we used empty_file.in to
test what the program would do when handed an empty file and non_word.in to
check what the program would do when given an input that isn't considered a 
word, both of these cases also passed without many issues. However when we
tried the testing our sensitive and insensitive commands (with our i_vs_s.in)
we noticed that while insensitve was working, insensitive was not. We realized
this was because we were just checking the key which we always lowered so
there was no sense of if the word was capitalized or not. We then added to our
struct a category for storing the original word and used that to check for
sensitive which worked. After that we tried testing what would happen if we
searched for a word that did not exist, at first the results were incorrect
and both printed the insensitive method, it honestly took us a while to realize
this was because we had set the condition for the print_not_match function
wrong and once we fixed the boolean match the actual search we were performing
this worked. We then checked if our @f command worked with newOutput.in (and
also scattered this command in a few other of our .in files after), it passed
that test file. Finally we tested multiple.in to see what our program would do
if it was asked for the same word multiple times and then another testing
file to see if a user typed multiple things to the command line (for ex.
'hi there, bye!') as there query, if the program would print query agian the
correct number of times it was supposed to (this was in same_line_query.in).

So far we had been testing on our personal directory and tinyData. When these
were working and we felt confident enough to move to smallGutenburg we realized
we were not building the program or at least not building it nearly fast
enough. eventually we realized this was because we were storing the entire
content of the line each word was found on in our struct. When we removed
this member of the struct and made a print function relying on line number and
file name it it the program was able to run all Gutenburgs. We were able to
figure this out from using the timer function referenced on piazza and is why
our .cpp has so many include statements (as it relied on a lot of things like
algorithms, chrono etc).

Also around this time that we realized we should test for the same word
appearing on the same line (ie duplicates.in). The case worked for when both
words on the line had the same capitalization, but not different.
Unfortunately, we were not able to figure out this case we tried to use sets
so words from each line number would only print once but our implementation was
unsuccessful. As a result we went back to an earlier autograder submission of
ours that (with more clean style) is the one you see here. We did not realize
that in this submission we forgot to comment out an if statement with no colon
after about the word "zoologica" (from a more minor bug we were testing). But
when we copied it back into VSCode and tried to take out things we didn't need
we noticed it kept seg faulting on smallGutenburg when we ran it after cleaning
when it hadn't before. So we went line by line deleting each thing we thought
was unnecessary and then running the command and we found that this was the
thing our program would always seg fault after deleting. To be honest we don't
understand why but that is why we left it in and eventually just wound up
using this eariler submission as newer ones that tried to handle duplicates
didn't work and often made our handingl of other cases worse. (Finally we
didn't check for errors opening files because we were told gerp did not have
to handle these cases). (NOTE we later took out the things with chrono
because of a build fail it caused).

(I) TIME SPENT
______________

We spent roughly 10 hours on phase 1 and the checkoff.

We spent about 25 hours on phase 2, so roughly 35 hours total.